{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of CE888 - Project 3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GurkiratSarna/CE888-Decision-Making-UoE/blob/master/Assignment_2/CE888_Assignment_2_Project_3_1900690.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB3yAuxfqgRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import tree\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt #plotting charts\n",
        "import pandas as pd #helps importing datasets\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from math import *\n",
        "import random\n",
        "from google.colab import files\n",
        "import io\n",
        "import os\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDPxCw_O9huO",
        "colab_type": "text"
      },
      "source": [
        "#Create Decision Tree classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vjh-DntU1lXI",
        "colab_type": "text"
      },
      "source": [
        "create_DT_classifier() function takes as input the complete dataset of N games and trains a Decision tree on it to return the classifier. \n",
        "\n",
        "The input data set is split into 70-30 percent for training and testing. A graph is plotted between accuracy and depth of the tree for 40 iterations only during the first run of the code. From this graph the depth of the tree which gives highest accuracy is used to train the classifiers for the complete project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSbikEdknrF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_DT_classifier(Data_in, get_depth, depth_max):\n",
        "    #Split data into 70-30 percent for training and testing\n",
        "    train_set, test_set = train_test_split(Data_in, test_size = 0.3, random_state=42)\n",
        "    \n",
        "    #Only take the features for training - 9 positions of the board and the player playing at the state\n",
        "    Data_train_x=train_set.iloc[:,0:10]\n",
        "    \n",
        "    #the output column extracted from the data for training\n",
        "    Data_train_y=train_set.iloc[:,-1]\n",
        "    Data_train_y=Data_train_y.astype('int')\n",
        "    \n",
        "    #Only take the features for testin - 9 positions of the board and the player playing at the state\n",
        "    Data_test_x=test_set.iloc[:,0:10]\n",
        "    \n",
        "    #the output column extracted from the data for testing\n",
        "    Data_test_y=test_set.iloc[:,-1]\n",
        "    Data_test_y=Data_test_y.astype('int')\n",
        "    \n",
        "    ########################\n",
        "    #Plotting graph for accuracy against the depth of the decision tree ranging from 0 to 39 (inclusive)\n",
        "    if(get_depth==1):\n",
        "        #print(\"in if get_depth==1 : \", get_depth)\n",
        "        depth_range = list(range(1,40))\n",
        "        accuracy_list = []\n",
        "        for depth in depth_range:\n",
        "            classifier_DT1 = DecisionTreeClassifier(criterion='gini',max_depth=depth,random_state=42)\n",
        "            classifier_DT1.fit(Data_train_x, Data_train_y)\n",
        "            score = classifier_DT1.score(Data_test_x, Data_test_y)\n",
        "            accuracy_list.append(score)\n",
        "        plt.plot(depth_range,accuracy_list, label='Accuracy') \n",
        "        plt.legend(framealpha=1, frameon=True)\n",
        "        plt.xlabel('Depth')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.show() \n",
        "        #Pick the depth at which accuracy is maximum only during the first run and train the classifier on that depth for the complete project.\n",
        "        depth_max =(accuracy_list.index(max(accuracy_list)) + 1)\n",
        "        print(\"maximum accuracy : \", max(accuracy_list))\n",
        "        print(\"depth of decision tree is : \", depth_max)\n",
        "    #########################'''\n",
        "    \n",
        "    #Train the classifier on the max accuracy in every iteration\n",
        "    classifier_DT = DecisionTreeClassifier(criterion='gini',max_depth=depth_max,random_state=42)\n",
        "    classifier_DT.fit(Data_train_x, Data_train_y)\n",
        "    Pred_test_y=classifier_DT.predict(Data_test_x)\n",
        "    #print(classification_report(Data_test_y,Pred_test_y)) # commented to save space for output\n",
        "\n",
        "    return classifier_DT, depth_max"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46iTScHP9n0Q",
        "colab_type": "text"
      },
      "source": [
        "#OXO Game to generate data sets\n",
        "The create_OXO_dataset() creates and returns a dataset of user provided N games. The dataset contains the state of all the games played with the player who is about to take a turn and the move that player takes. During the first run, the moves are randomly decided, however later the moves are predicted by a DT classifier 90% of the times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTTExuwIPSQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is a very simple implementation of the UCT Monte Carlo Tree Search algorithm in Python 2.7.\n",
        "# The function UCT(rootstate, itermax, verbose = False) is towards the bottom of the code.\n",
        "# It aims to have the clearest and simplest possible code, and for the sake of clarity, the code\n",
        "# is orders of magnitude less efficient than it could be made, particularly by using a \n",
        "# state.GetRandomMove() or state.DoRandomRollout() function.\n",
        "# \n",
        "# Example GameState classes for Nim, OXO and Othello are included to give some idea of how you\n",
        "# can write your own GameState use UCT in your 2-player game. Change the game to be played in \n",
        "# the UCTPlayGame() function at the bottom of the code.\n",
        "# \n",
        "# Written by Peter Cowling, Ed Powley, Daniel Whitehouse (University of York, UK) September 2012.\n",
        "# \n",
        "# Licence is granted to freely use and distribute for any sensible/legal purpose so long as this comment\n",
        "# remains in any distributed code.\n",
        "# \n",
        "class OXOState:\n",
        "    \"\"\" A state of the game, i.e. the game board.\n",
        "        Squares in the board are in this arrangement\n",
        "        012\n",
        "        345\n",
        "        678\n",
        "        where 0 = empty, 1 = player 1 (X), 2 = player 2 (O)\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.playerJustMoved = 2 # At the root pretend the player just moved is 2 whereas player 1 has the first move.\n",
        "        self.board = [0,0,0,0,0,0,0,0,0] # 0 = empty, 1 = player 1, 2 = player 2. This is the initial board state - all positions are empty.\n",
        "        \n",
        "    def Clone(self):\n",
        "        \"\"\" Create a deep clone of this game state.\n",
        "        \"\"\"\n",
        "        st = OXOState()\n",
        "        st.playerJustMoved = self.playerJustMoved\n",
        "        st.board = self.board[:]\n",
        "        return st\n",
        "\n",
        "    def DoMove(self, move):\n",
        "        \"\"\" Update the state board by replacing 0 with the player playing the move at the position/move of the board.\n",
        "            Must update playerJustMoved.\n",
        "        \"\"\"\n",
        "        assert move >= 0 and move <= 8 and move == int(move) and self.board[move] == 0\n",
        "        self.playerJustMoved = 3 - self.playerJustMoved\n",
        "        self.board[move] = self.playerJustMoved\n",
        "        \n",
        "    def GetMoves(self):\n",
        "        \"\"\" Get all possible moves from this state. That is return all the positional values of the zroes in the state board.\n",
        "        \"\"\"\n",
        "        return [i for i in range(9) if self.board[i] == 0]\n",
        "    \n",
        "    def GetResult(self, playerjm):\n",
        "        \"\"\" Get the game result from the viewpoint of playerjm. \n",
        "        \"\"\"\n",
        "        for (x,y,z) in [(0,1,2),(3,4,5),(6,7,8),(0,3,6),(1,4,7),(2,5,8),(0,4,8),(2,4,6)]:\n",
        "            #Winning possibilities of the board\n",
        "            if self.board[x] == self.board[y] == self.board[z]: # check if values in all the 3 positions is of the same player\n",
        "                # check if the player that just moved is same as the value in the winning positions, if yes return 1 else 0 stating that the other player wins.\n",
        "                if self.board[x] == playerjm: \n",
        "                    return 1.0\n",
        "                else:\n",
        "                    return 0.0\n",
        "        if self.GetMoves() == []:\n",
        "          return 0.5 # draw\n",
        "        return False # Should not be possible to get here\n",
        "\n",
        "    def __repr__(self): # This is how the return value is defined for this class.\n",
        "        s= \"\"\n",
        "        for i in range(9): \n",
        "            s += \".XO\"[self.board[i]] # . for 0, X for 1 and O for 2 positional values\n",
        "            if i % 3 == 2: s += \"\\n\"\n",
        "        return s\n",
        "\n",
        "\n",
        "class Node:\n",
        "    \"\"\" A node in the game tree. Note : wins is always from the viewpoint of playerJustMoved.\n",
        "        Crashes if state not specified.\n",
        "    \"\"\"\n",
        "    def __init__(self, move = None, parent = None, state = None):\n",
        "        self.move = move # the move that got us to this node - \"None\" for the root node\n",
        "        #parentNode stores all the parents from the rootnode until the current node for backpropogation, during which it deletes until it is None.\n",
        "        self.parentNode = parent # \"None\" for the root node.\n",
        "        self.childNodes = []\n",
        "        self.wins = 0\n",
        "        self.visits = 0 #The number of itermax passed\n",
        "        self.untriedMoves = state.GetMoves() # future child nodes. The available positions to be played at any point of the game.\n",
        "        self.playerJustMoved = state.playerJustMoved # the only part of the state that the Node needs later\n",
        "        \n",
        "    def UCTSelectChild(self):\n",
        "        \"\"\" Use the UCB1 formula to select a child node. Often a constant UCTK is applied so we have\n",
        "            lambda c: c.wins/c.visits + UCTK * sqrt(2*log(self.visits)/c.visits to vary the amount of\n",
        "            exploration versus exploitation.\n",
        "        \"\"\"\n",
        "        s = sorted(self.childNodes, key = lambda c: c.wins/c.visits + sqrt(2*log(self.visits)/c.visits))[-1] #pick the highest\n",
        "        return s\n",
        "    \n",
        "    def AddChild(self, m, s):\n",
        "        \"\"\" Remove m from untriedMoves and add a new child node for this move.\n",
        "            Return the added child node.\n",
        "        \"\"\"\n",
        "        n = Node(move = m, parent = self, state = s)\n",
        "        self.untriedMoves.remove(m)\n",
        "        self.childNodes.append(n)\n",
        "        return n\n",
        "    \n",
        "    def Update(self, result):\n",
        "        \"\"\" Update this node - one additional visit and result additional wins. result must be from the viewpoint of playerJustmoved.\n",
        "        \"\"\"\n",
        "        self.visits += 1\n",
        "        self.wins += result\n",
        "\n",
        "    def __repr__(self): # Added other variables to be returned to check the flow of the variable during testing small iterations.\n",
        "        return \"[M:\" + str(self.move) + \" W/V:\" + str(self.wins) + \"/\" + str(self.visits) + \" U:\" + str(self.untriedMoves) + \" PJM:\" + str(self.playerJustMoved) + \"]\"\n",
        "\n",
        "    def TreeToString(self, indent):\n",
        "        s = self.IndentString(indent) + str(self)\n",
        "        for c in self.childNodes:\n",
        "             s += c.TreeToString(indent+1)\n",
        "        return s\n",
        "\n",
        "    def IndentString(self,indent):\n",
        "        s = \"\\n\"\n",
        "        for i in range (1,indent+1):\n",
        "            s += \"| \"\n",
        "        return s\n",
        "\n",
        "    def ChildrenToString(self):\n",
        "        s = \"\"\n",
        "        for c in self.childNodes:\n",
        "             s += str(c) + \"\\n\"\n",
        "        return s\n",
        "\n",
        "def GetRandomMove(s,c_dt):\n",
        "    \"\"\"We will pick a random value between 0.0 and 1.0. Considering there is a normal distribution between these values, \n",
        "       if we get a value between 0.0 and 0.9 then the decision tree classifier decides the next move on the given state otherwise a random integer is returned.\n",
        "    \"\"\"\n",
        "    \n",
        "    rand_num=random.uniform(0.0, 1.0)\n",
        "\n",
        "    if rand_num <= 0.9:\n",
        "        temp_list=list(s.board)\n",
        "        temp_list.append(s.playerJustMoved)\n",
        "        #print(temp_list)\n",
        "\n",
        "        #print([s.board])\n",
        "        next_move=c_dt.predict([temp_list])\n",
        "        next_move=next_move[0]\n",
        "    \n",
        "        #If the move decided by decision tree classifier is not in the untried moves then we select randomly the next eligible move.\n",
        "        if next_move not in s.GetMoves():\n",
        "            next_move=random.choice(s.GetMoves())\n",
        "            \"\"\"Add the move taken at this state to a global list 'train_state'.\n",
        "               These are unexepected states that will be combined with the dataset, containing 2000 game states, to train the model in next iteration.\n",
        "            \"\"\"\n",
        "            st_board=list(s.board) #so that it does not point to the same memory address\n",
        "            st_board.append(s.playerJustMoved)\n",
        "            st_board.append(next_move) # append the random move at this state\n",
        "            train_state.append(st_board)            \n",
        "    else:\n",
        "        next_move=random.choice(s.GetMoves())\n",
        "    return next_move\n",
        "    \n",
        "def UCT(firstrun, classifier_dt, rootstate, itermax, verbose = False):\n",
        "    \"\"\" Conduct a UCT search for itermax iterations starting from rootstate.\n",
        "        Return the best move from the rootstate.\n",
        "        Assumes 2 alternating players (player 1 starts), with game results in the range [0.0, 1.0].\"\"\"\n",
        "\n",
        "    rootnode = Node(state = rootstate)\n",
        "\n",
        "    for i in range(itermax):\n",
        "        node = rootnode\n",
        "        state = rootstate.Clone()\n",
        "\n",
        "        # Select\n",
        "        while node.untriedMoves == [] and node.childNodes != []: # node is fully expanded and non-terminal\n",
        "            node = node.UCTSelectChild()\n",
        "            state.DoMove(node.move)\n",
        "\n",
        "        # Expand\n",
        "        if node.untriedMoves != []:  # if we can expand (i.e. state/node is non-terminal)\n",
        "            m = random.choice(node.untriedMoves) \n",
        "            state.DoMove(m)\n",
        "            node = node.AddChild(m, state)  # add child and descend tree. This updates the parent node as well.\n",
        "\n",
        "        # Rollout\n",
        "        '''Game is played considering all eligible moves after the move chosen in Expand step.\n",
        "        In every step of this game, a child node and parent node is added to form a tree. Once all possible branches are created the best move is returned\n",
        "        using the UCB1 formula in UCTSelectChild() function.'''\n",
        "        while state.GetMoves() != []: # while state is non-terminal\n",
        "            if firstrun==1: # if the code is executed from the scratch and no initial input file of states is given.\n",
        "                r=random.choice(state.GetMoves())\n",
        "            else:\n",
        "                r=GetRandomMove(state, classifier_dt)\n",
        "            state.DoMove(r)\n",
        "        \n",
        "        # Backpropagate\n",
        "        while node != None: # backpropagate from the expanded node and work back to the root node\n",
        "            gr=state.GetResult(node.playerJustMoved)\n",
        "            node.Update(gr) # state is terminal. Update node with result from POV of node.playerJustMoved\n",
        "            node = node.parentNode\n",
        "\n",
        "    # Output some information about the tree - Commented to save space for the output\n",
        "    #if verbose: print(rootnode.TreeToString(0))\n",
        "    #else: print(rootnode.ChildrenToString())\n",
        "    \n",
        "    ret=sorted(rootnode.childNodes, key = lambda c: c.visits)[-1].move\n",
        "\n",
        "    return ret # return the move that was most visited as the best move.\n",
        "                \n",
        "def UCTPlayGame(firstrun, classifier_dt): #These simulations are MCTS\n",
        "    \"\"\" Play a sample game between two UCT players where each player gets a different number \n",
        "        of UCT iterations (= simulations = tree nodes).\n",
        "    \"\"\"\n",
        "    state = OXOState()\n",
        "  \n",
        "    tempdataset=[[0,0,0,0,0,0,0,0,0]] #  A temporary datset which will accumulate all the stages of one game\n",
        "    # A list of best moves for that particular game. This will always have length of tempdataset-1 because of the initial stage in the temporary dataset.\n",
        "    bestmovelist=[] #\n",
        "    pjm_list=[] #List of player moving at the current board\n",
        "    while state.GetMoves() != []:\n",
        "        #print(str(state)) # prints the board. Commented to save the space for output visibility.\n",
        "        \n",
        "        '''We introduce bias towards player 1 because we associate player 1 to the most learnt Decision Tree (later).\n",
        "        The bias is introduced by increasing the itermax value in 'else' as compared to itermax value in 'if' for player 2'''\n",
        "        '''For assignment 2, we remove the bias to have a fair play between both the players and to ralise the learning'''\n",
        "        '''1000:2000 -> No one wins; 1500:2000 -> No one wins; 10:1000 -> nearly 2.5% winning - Assignment 1\n",
        "        10:1000 -> with 5000 iterations of UCTPlaygame -> 12.5% winning games - Assignment 1'''\n",
        "        if state.playerJustMoved == 1: #The consition checks for player 1 but the best move is returned for player 2.\n",
        "            m = UCT(firstrun, classifier_dt, rootstate=state, itermax=100, verbose=False)  # play with values for itermax and verbose = True.\n",
        "        else:\n",
        "            m = UCT(firstrun, classifier_dt, rootstate=state, itermax=100, verbose=False) # itermax decides the total value of visits to one node in a given game.\n",
        "        #print(\"Best Move: \" + str(m) + \"\\n\") # Commented to save space for the output\n",
        "        state.DoMove(m)\n",
        "        \n",
        "        pjm_list.append(state.playerJustMoved)\n",
        "        bestmovelist.append(m)\n",
        "        tempdataset.append(list(state.board))\n",
        "        \n",
        "        if state.GetResult(state.playerJustMoved) != False:\n",
        "            #print(str(state)) # Commented to save space for the output\n",
        "            break\n",
        "    \n",
        "    if state.GetResult(state.playerJustMoved) == 1.0:\n",
        "        #print(\"Player \" + str(state.playerJustMoved) + \" wins!\") #Commented to save space for the output\n",
        "        winner=state.playerJustMoved\n",
        "    elif state.GetResult(state.playerJustMoved) == 0.0:\n",
        "        #print(\"Player \" + str(3 - state.playerJustMoved) + \" wins!\") #Commented to save space for the output\n",
        "        winner=(3-state.playerJustMoved)\n",
        "    else: \n",
        "      #print(\"Nobody wins!\") #Commented to save space for the output\n",
        "      winner=0\n",
        "\n",
        "    ''' This lists will always have one element less compared to tempdataset because the last state of the game will never have any move or player\n",
        "    associated to it.\n",
        "    Because we are combining the three lists so we want them of equal length hence the move and player at the last stage will be NaN, \n",
        "    The last game state will be removed later from the final dataframe.'''\n",
        "    bestmovelist.append('NaN')\n",
        "    pjm_list.append('NaN')\n",
        "\n",
        "    for i in range(len(tempdataset)): \n",
        "      tempdataset[i].append(pjm_list[i]) #Append the Player at the board state\n",
        "      tempdataset[i].append(bestmovelist[i]) # Append the move taken at every stage.\n",
        "\n",
        "    return tempdataset, winner \n",
        "\n",
        "def create_OXO_dataset(num_games, firstrun, classifier_dt):\n",
        "    \"\"\" Play a single game to the end using UCT for both players. \n",
        "    \"\"\"\n",
        "    finaldataset=[] # A list of lists of the game stages. Each list is one game, representing the lists of stages returned.\n",
        "    finaldataset1=[] # A list of all the stages of the games in the finaldataset. It is the output of converting a list of list into one list.\n",
        "    \n",
        "    p1win=0\n",
        "    p2win=0\n",
        "    Nowin=0\n",
        "    winner=0\n",
        "    for i in range(num_games): # Run the UCTPlayGame 2000 times.\n",
        "      returnds, winner =UCTPlayGame(firstrun, classifier_dt) # returnds stores the game temporarily.\n",
        "      finaldataset.append(returnds) \n",
        "      if winner==1:\n",
        "        p1win+=1\n",
        "      elif winner==2:\n",
        "        p2win+=1\n",
        "      else:\n",
        "        Nowin+=1\n",
        "\n",
        "    #Convert list of lists to one list\n",
        "    for i in finaldataset:  \n",
        "      for j in i:  \n",
        "        finaldataset1.append(j) \n",
        "\n",
        "    #Name the columns of the finaldataset1 and convert it into a dataframe.\n",
        "    datatbp=pd.DataFrame(finaldataset1, columns=['0th pos', '1st pos', '2nd pos', '3rd pos', '4th pos', '5th pos', '6th pos', '7th pos', '8th pos', 'Player', 'Move'])\n",
        "     \n",
        "    #Remove the rows that have 'NaN' as these are the rows depicting the last stage of the game with no move.\n",
        "    datatbp.drop(datatbp[datatbp.Move == 'NaN'].index, inplace=True)\n",
        "    datatbp.reset_index(drop=True, inplace=True) #  Reset the row index of the data frame\n",
        "\n",
        "    #print(\"Wins : Player1 : \", p1win, \" Player2 : \", p2win, \" Nobody wins : \", Nowin) #Commented to save space for the output\n",
        "    \n",
        "    return datatbp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OxFMCsF96xe",
        "colab_type": "text"
      },
      "source": [
        "#Classifiers collection\n",
        "create_classifier_dict() function creates the dictionary of classifiers for each dataset of N games played. The num_datasets is a value for the number of datasets/classifiers (number of datsets of N games each) needed in a dictionary in one iteration.\n",
        "The first_file variable is to track if the user is providing with the innitial dataset or not. If not, then the first file is created and downloaded. However not all datasets are downloaded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKUDFU5ZbxLX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_classifier_dict(num_datasets, num_of_games, first_file, Data_user):\n",
        "   \n",
        "   get_depth=1\n",
        "   depth_max=0\n",
        "   dict_classifier=dict()\n",
        "   classifier=None\n",
        "   \n",
        "   \"\"\"firstrun is a flag depicting if the code is going to create a dataset of 2000 games for the first time or not. \n",
        "      1 means it is a first run and 0 means it is not.\n",
        "   \"\"\"\n",
        "   if (first_file==1):\n",
        "       classifier, depth_max =create_DT_classifier(Data_user, get_depth, depth_max)\n",
        "\n",
        "       dict_classifier[int('0')]=classifier\n",
        "\n",
        "       num_datasets=num_datasets-1\n",
        "       firstrun=0\n",
        "       get_depth=0\n",
        "   else:\n",
        "       firstrun=1\n",
        "    \n",
        "   for i in range(num_datasets):\n",
        "       #print('Value of i : ', i)\n",
        "       data_tbp=create_OXO_dataset(num_of_games, firstrun, classifier) # Is this imitation learning that includes the apprentice policy and expert policy creation ?\n",
        "       #print(train_state)\n",
        "       comb_train_state=pd.DataFrame(train_state,columns=['0th pos', '1st pos', '2nd pos', '3rd pos', '4th pos', '5th pos', '6th pos', '7th pos', '8th pos', 'Player','Move'])\n",
        "       data_tbp=pd.concat([data_tbp,comb_train_state],ignore_index=True, axis=0)\n",
        "       if(firstrun==1):\n",
        "           data_tbp.to_csv('CE888_DataToBeProcessed_1900690.csv')\n",
        "           files.download('CE888_DataToBeProcessed_1900690.csv') \n",
        "       #combine the data_tbp and train_state here and then create a classifier\n",
        "       classifier, depth_max =create_DT_classifier(data_tbp, get_depth, depth_max)\n",
        "\n",
        "       \n",
        "       if(first_file==1):\n",
        "           dict_classifier.update({i+1:classifier})\n",
        "       else:\n",
        "           dict_classifier.update({i:classifier})\n",
        "       \n",
        "       firstrun=0\n",
        "       get_depth=0\n",
        "       train_state.clear()\n",
        "   return dict_classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFtC8DKlpo_N",
        "colab_type": "text"
      },
      "source": [
        "#OXO Game for Classifiers - Tournaments\n",
        "Below is a modified version of OXO game to have the classifiers play against each other. The class Node and OXOstate have not been redefined. We associate player 1 with every 10th classifier and player 2 with it's previous 9 versions of the classifier. That is tenth DT classifier (DT10) will play against first DT classifier (DT1) then with DT2 and so on until DT9. After every iteration we calculate the number of times DT10 wins against DT1, DT2...DT9. Player 1 always plays with DT10 decisions and player 2 plays with DT1, DT2...DT9 decisions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3rhKXTSFdnL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def GetRandomMove1(DTclassifier, s):\n",
        "    temp_list=list(s.board)\n",
        "    temp_list.append(s.playerJustMoved)\n",
        "    #print(temp_list)\n",
        "    #print(s.board)\n",
        "    r=DTclassifier.predict([temp_list])\n",
        "    r=r[0]\n",
        "    if r not in s.GetMoves():\n",
        "        r=random.choice(s.GetMoves())\n",
        "    return r\n",
        "\n",
        "def UCT1(pl1_classifier, pl2_classifier,rootstate, itermax, verbose = False):\n",
        "    \"\"\" Conduct a UCT search for itermax iterations starting from rootstate.\n",
        "        Return the best move from the rootstate.\n",
        "        Assumes 2 alternating players (player 1 starts), with game results in the range [0.0, 1.0].\"\"\"\n",
        "\n",
        "    rootnode = Node(state = rootstate)\n",
        "\n",
        "    for i in range(itermax):\n",
        "        node = rootnode\n",
        "        state = rootstate.Clone()\n",
        "\n",
        "        # Select\n",
        "        while node.untriedMoves == [] and node.childNodes != []: # node is fully expanded and non-terminal\n",
        "            node = node.UCTSelectChild()\n",
        "            state.DoMove(node.move)\n",
        "\n",
        "        # Expand\n",
        "        if node.untriedMoves != []: # if we can expand (i.e. state/node is non-terminal)            \n",
        "            m = random.choice(node.untriedMoves)\n",
        "            state.DoMove(m)\n",
        "            node = node.AddChild(m,state) # add child and descend tree\n",
        "\n",
        "        # Rollout \n",
        "        while state.GetMoves() != []: # while state is non-terminal\n",
        "\n",
        "            if(state.playerJustMoved==1):\n",
        "                r=GetRandomMove1(pl1_classifier,state)\n",
        "            else:\n",
        "                r=GetRandomMove1(pl2_classifier,state)\n",
        "            state.DoMove(r)\n",
        "\n",
        "        # Backpropagate\n",
        "        while node != None: # backpropagate from the expanded node and work back to the root node\n",
        "            node.Update(state.GetResult(node.playerJustMoved)) # state is terminal. Update node with result from POV of node.playerJustMoved\n",
        "            node = node.parentNode\n",
        "\n",
        "    # Output some information about the tree - Commented to save space for Output\n",
        "    #if (verbose): print(rootnode.TreeToString(0))\n",
        "    #else: print(rootnode.ChildrenToString())\n",
        "\n",
        "    return sorted(rootnode.childNodes, key = lambda c: c.visits)[-1].move # return the move that was most visited\n",
        "                \n",
        "def UCTPlayGame1(pl1_classifier, pl2_classifier):\n",
        "    \"\"\" Play a sample game between two UCT players where each player gets a different number \n",
        "        of UCT iterations (= simulations = tree nodes).\n",
        "    \"\"\"\n",
        "    \n",
        "    state = OXOState() \n",
        "    \n",
        "    while (state.GetMoves() != []):\n",
        "        #print(str(state)) #Commented to save space for Output\n",
        "        if state.playerJustMoved == 1:\n",
        "            m = UCT1(pl1_classifier, pl2_classifier,rootstate = state, itermax = 100, verbose = False) \n",
        "        else:\n",
        "            m = UCT1(pl1_classifier, pl2_classifier, rootstate = state, itermax =100, verbose = False)\n",
        "        #print(\"Best Move: \" + str(m) + \"\\n\") #Commented to save space for Output\n",
        "        state.DoMove(m)\n",
        "        if state.GetResult(state.playerJustMoved) != False:\n",
        "            #print(str(state)) #Commented to save space for Output\n",
        "            break\n",
        "    if state.GetResult(state.playerJustMoved) == 1.0:\n",
        "        #print(\"Player \" + str(state.playerJustMoved) + \" wins!\") #Commented to save space for Output\n",
        "        return state.playerJustMoved\n",
        "    elif state.GetResult(state.playerJustMoved) == 0.0:\n",
        "        #print(\"Player \" + str(3 - state.playerJustMoved) + \" wins!\") #Commented to save space for Output\n",
        "        return (3-state.playerJustMoved)\n",
        "    else:\n",
        "        #print(\"Nobody wins!\") #Commented to save space for Output\n",
        "        return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdjNZQpcqZSu",
        "colab_type": "text"
      },
      "source": [
        "#Main\n",
        "The user is asked to enter the number of games N and the number of datsets Y. Also they are asked if they will be providing the initial dataset or not. For creation of initial dataset the code is provided later in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qak6MwDoezzr",
        "colab_type": "code",
        "outputId": "88238e10-1991-4e7d-c25c-ae34bfba000e",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 438
        }
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        " \n",
        "  # create a global list to record the unexpected states encountered by the Decision tree. These are states for which DT could not give an eligible move.\n",
        "   \n",
        "  global train_state\n",
        "  train_state=[]\n",
        "  \n",
        "  no_of_games=int(input(\"Please enter the number of games to be played to create a single data set of states: \"))\n",
        "  no_of_clsfr=int(input('Please enter the number of datasets required to be created (multiple of 10). Each dataset is a collection of states of a number of OXO games : '))\n",
        "  first_file=int(input(\"Will you provide the initial datset (Yes=1;No=0) : \"))\n",
        "\n",
        "\n",
        "  if(first_file==1):\n",
        "    uploaded = files.upload()\n",
        "    fname=input('Enter csv file name with extention and no path : ')\n",
        "    Data_user = pd.read_csv(io.BytesIO(uploaded[fname]))\n",
        "  else:\n",
        "    Data_user = 0\n",
        "  \n",
        "  dict_clfr=create_classifier_dict(no_of_clsfr, no_of_games, first_file, Data_user)\n",
        "  #print('Length of dictionary : ', len(dict_clfr))\n",
        "  #print('dictionary : ', dict_clfr)\n",
        "  k=1\n",
        "  for i in range(0,len(dict_clfr),10):\n",
        "      DT10=0\n",
        "      DTother=0\n",
        "      Nowin=0\n",
        "      j=i\n",
        "      for j in range(i, i+9): # execute from 0 until 8th index of every tenth position\n",
        "          winner = UCTPlayGame1(dict_clfr[9+10*(i//10)], dict_clfr[j]) # transfer 9 always and every value from 0 to 8\n",
        "          #print(winner)\n",
        "          if winner==1:\n",
        "            #print('DT10 wins')\n",
        "            DT10+=1\n",
        "          elif winner==2:\n",
        "            #print('DT',i+1,' wins')\n",
        "            DTother+=1\n",
        "          else:\n",
        "            #print('No wins')\n",
        "            Nowin+=1\n",
        "      print(\"Tournament \",k,\" Wins : \\n DT10 : \", DT10, \" Other DTs : \", DTother, \" No wins : \", Nowin)\n",
        "      k+=1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please enter the number of games to be played to create a single data set of states: 100\n",
            "Please enter the number of datasets required to be created (multiple of 10). Each dataset is a collection of states of a number of OXO games : 100\n",
            "Will you provide the initial datset (Yes=1;No=0) : 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-702a68be-aa98-4c16-a60b-7a1963689ed9\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-702a68be-aa98-4c16-a60b-7a1963689ed9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving CE888_DataToBeProcessed_1900690_biased1.csv to CE888_DataToBeProcessed_1900690_biased1 (2).csv\n",
            "Enter csv file name with extention and no path : CE888_DataToBeProcessed_1900690_biased1.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "maximum accuracy :  0.47787149849005517\n",
            "depth of decision tree is :  13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ur4U_2SFmmqR",
        "colab_type": "text"
      },
      "source": [
        "#Creation of Initial DataSet Code\n",
        "The code has been commented because it has similar attributes and functions to the OXO Game in cell 2. To create an intial dataset, the below code needs to be copied in a separate Jupyter Notebook and the dataset be downloaded.\n",
        "\n",
        "To change the numbe r of games, please update the number in below line :\n",
        "\n",
        "for i in range(5000): # LINE ADDED. Run the UCTPlayGame 2000 or 5000 times.\n",
        "\n",
        "This code was executed to create the biased initial dataset for the research done above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt6CnVswmv0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "class OXOState:\n",
        "    \"\"\" A state of the game, i.e. the game board.\n",
        "        Squares in the board are in this arrangement\n",
        "        012\n",
        "        345\n",
        "        678\n",
        "        where 0 = empty, 1 = player 1 (X), 2 = player 2 (O)\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.playerJustMoved = 2 # At the root pretend the player just moved is 2 whereas player 1 has the first move.\n",
        "        self.board = [0,0,0,0,0,0,0,0,0] # 0 = empty, 1 = player 1, 2 = player 2. This is the initial board state - all positions are empty.\n",
        "        \n",
        "    def Clone(self):\n",
        "        \"\"\" Create a deep clone of this game state.\n",
        "        \"\"\"\n",
        "        st = OXOState()\n",
        "        st.playerJustMoved = self.playerJustMoved\n",
        "        st.board = self.board[:]\n",
        "        return st\n",
        "\n",
        "    def DoMove(self, move):\n",
        "        \"\"\" Update the state board by replacing 0 with the player playing the move at the position/move of the board.\n",
        "            Must update playerJustMoved.\n",
        "        \"\"\"\n",
        "        assert move >= 0 and move <= 8 and move == int(move) and self.board[move] == 0\n",
        "        self.playerJustMoved = 3 - self.playerJustMoved\n",
        "        self.board[move] = self.playerJustMoved\n",
        "        \n",
        "    def GetMoves(self):\n",
        "        \"\"\" Get all possible moves from this state. That is return all the positional values of the zroes in the state board.\n",
        "        \"\"\"\n",
        "        return [i for i in range(9) if self.board[i] == 0]\n",
        "    \n",
        "    def GetResult(self, playerjm):\n",
        "        \"\"\" Get the game result from the viewpoint of playerjm. \n",
        "        \"\"\"\n",
        "        for (x,y,z) in [(0,1,2),(3,4,5),(6,7,8),(0,3,6),(1,4,7),(2,5,8),(0,4,8),(2,4,6)]: #Winning possibilities of the board\n",
        "            if self.board[x] == self.board[y] == self.board[z]: # check if values in all the 3 positions is of the same player\n",
        "                # check if the player that just moved is same as the value in the winning positions, if yes return 1 else 0 stating that the other player wins.\n",
        "                if self.board[x] == playerjm: \n",
        "                    return 1.0\n",
        "                else:\n",
        "                    return 0.0\n",
        "        if self.GetMoves() == []:\n",
        "          return 0.5 # draw\n",
        "        return False # Should not be possible to get here\n",
        "\n",
        "    def __repr__(self): # This is how the return value is defined for this class.\n",
        "        s= \"\"\n",
        "        for i in range(9): \n",
        "            s += \".XO\"[self.board[i]] # . for 0, X for 1 and O for 2 positional values\n",
        "            if i % 3 == 2: s += \"\\n\"\n",
        "        return s\n",
        "\n",
        "\n",
        "class Node:\n",
        "    \"\"\" A node in the game tree. Note : wins is always from the viewpoint of playerJustMoved.\n",
        "        Crashes if state not specified.\n",
        "    \"\"\"\n",
        "    def __init__(self, move = None, parent = None, state = None):\n",
        "        self.move = move # the move that got us to this node - \"None\" for the root node\n",
        "        #parentNode stores all the paarents from the rootnode until the current node for backpropogation which then deletes until it is None.\n",
        "        self.parentNode = parent # \"None\" for the root node.\n",
        "        self.childNodes = []\n",
        "        self.wins = 0\n",
        "        self.visits = 0 #The number of itermax passed\n",
        "        self.untriedMoves = state.GetMoves() # future child nodes. The available positions to be played at any point of the game.\n",
        "        self.playerJustMoved = state.playerJustMoved # the only part of the state that the Node needs later\n",
        "        \n",
        "    def UCTSelectChild(self):\n",
        "        \"\"\" Use the UCB1 formula to select a child node. Often a constant UCTK is applied so we have\n",
        "            lambda c: c.wins/c.visits + UCTK * sqrt(2*log(self.visits)/c.visits to vary the amount of\n",
        "            exploration versus exploitation.\n",
        "        \"\"\"\n",
        "        s = sorted(self.childNodes, key = lambda c: c.wins/c.visits + sqrt(2*log(self.visits)/c.visits))[-1]\n",
        "        return s\n",
        "    \n",
        "    def AddChild(self, m, s):\n",
        "        \"\"\" Remove m from untriedMoves and add a new child node for this move.\n",
        "            Return the added child node.\n",
        "        \"\"\"\n",
        "        n = Node(move = m, parent = self, state = s)\n",
        "        self.untriedMoves.remove(m)\n",
        "        self.childNodes.append(n)\n",
        "        return n\n",
        "    \n",
        "    def Update(self, result):\n",
        "        \"\"\" Update this node - one additional visit and result additional wins. result must be from the viewpoint of playerJustmoved.\n",
        "        \"\"\"\n",
        "        self.visits += 1\n",
        "        self.wins += result\n",
        "\n",
        "    def __repr__(self): # Added other variables to be retiurned to check the flow of the variable during testing small iterations.\n",
        "        return \"[M:\" + str(self.move) + \" W/V:\" + str(self.wins) + \"/\" + str(self.visits) + \" U:\" + str(self.untriedMoves) + \" PJM:\" + str(self.playerJustMoved) + \"]\"\n",
        "\n",
        "    def TreeToString(self, indent):\n",
        "        s = self.IndentString(indent) + str(self)\n",
        "        for c in self.childNodes:\n",
        "             s += c.TreeToString(indent+1)\n",
        "        return s\n",
        "\n",
        "    def IndentString(self,indent):\n",
        "        s = \"\\n\"\n",
        "        for i in range (1,indent+1):\n",
        "            s += \"| \"\n",
        "        return s\n",
        "\n",
        "    def ChildrenToString(self):\n",
        "        s = \"\"\n",
        "        for c in self.childNodes:\n",
        "             s += str(c) + \"\\n\"\n",
        "        return s\n",
        "\n",
        "\n",
        "def UCT(rootstate, itermax, verbose = False):\n",
        "    \"\"\" Conduct a UCT search for itermax iterations starting from rootstate.\n",
        "        Return the best move from the rootstate.\n",
        "        Assumes 2 alternating players (player 1 starts), with game results in the range [0.0, 1.0].\"\"\"\n",
        "\n",
        "    rootnode = Node(state = rootstate)\n",
        "\n",
        "    for i in range(itermax):\n",
        "        node = rootnode\n",
        "        state = rootstate.Clone()\n",
        "\n",
        "        # Select\n",
        "        while node.untriedMoves == [] and node.childNodes != []: # node is fully expanded and non-terminal\n",
        "            node = node.UCTSelectChild()\n",
        "            state.DoMove(node.move)\n",
        "\n",
        "        # Expand\n",
        "        if node.untriedMoves != []:  # if we can expand (i.e. state/node is non-terminal)\n",
        "            m = random.choice(node.untriedMoves) \n",
        "            state.DoMove(m)\n",
        "            node = node.AddChild(m, state)  # add child and descend tree. This updates the parent node as well.\n",
        "\n",
        "        # Rollout - this can often be made orders of magnitude quicker using a state.GetRandomMove() function.\n",
        "        # This loop will play a game within the random move picked up before and then return the best move for one chance of the actual game being played.\n",
        "        while state.GetMoves() != []: # while state is non-terminal\n",
        "            #print(\"IN ROLLOUT\")\n",
        "            state.DoMove(random.choice(state.GetMoves()))\n",
        "\n",
        "        # Backpropagate\n",
        "        while node != None: # backpropagate from the expanded node and work back to the root node\n",
        "            node.Update(state.GetResult(node.playerJustMoved)) # state is terminal. Update node with result from POV of node.playerJustMoved\n",
        "            node = node.parentNode\n",
        "\n",
        "    # Output some information about the tree - can be omitted\n",
        "    #if verbose: print(rootnode.TreeToString(0))\n",
        "    #else: print(rootnode.ChildrenToString())\n",
        "\n",
        "    return sorted(rootnode.childNodes, key = lambda c: c.visits)[-1].move # return the move that was most visited as the best move.\n",
        "                \n",
        "def UCTPlayGame():\n",
        "    \"\"\" Play a sample game between two UCT players where each player gets a different number \n",
        "        of UCT iterations (= simulations = tree nodes).\n",
        "    \"\"\"\n",
        "    state = OXOState()\n",
        "\n",
        "    tempdataset=[[0,0,0,0,0,0,0,0,0]] # LINE ADDED. A temporary datset which will accumulate all the stages of one game\n",
        "    # A list of best moves for that particular game. This will always have length of tempdataset-1 because of the initial stage in the temporary dataset.\n",
        "    bestmovelist=[] # LINE ADDED.\n",
        "    pjm_list=[] #List of player moving at the current board\n",
        "    while state.GetMoves() != []:\n",
        "        print(str(state)) # prints the board - Uncomment\n",
        "        if state.playerJustMoved == 1:\n",
        "            # Biased towards one player so that someone wins. \n",
        "            #1000:2000 -> No one wins; 1500:2000 -> No one wins; 10:1000 -> nearly 2.5% winning\n",
        "            #10:1000 -> with 5000 iterations of UCTPlaygame -> 12.5% winning games\n",
        "            m = UCT(rootstate=state, itermax=10, verbose=False)  # play with values for itermax and verbose = True.\n",
        "            #print(\"In 10 itermax\")\n",
        "        else:\n",
        "            m = UCT(rootstate=state, itermax=1000, verbose=False) # itermax decides the total value of visits to one node in a given game.\n",
        "            print(\"In 5 itermax\")\n",
        "        #print(\"Best Move: \" + str(m) + \"\\n\") # Uncomment\n",
        "        state.DoMove(m)\n",
        "        \n",
        "\n",
        "        pjm_list.append(state.playerJustMoved)\n",
        "        bestmovelist.append(m) # LINE ADDED. \n",
        "        tempdataset.append(list(state.board))  #LINE ADDED.\n",
        "        \n",
        "        if state.GetResult(state.playerJustMoved) != False:\n",
        "            #print(str(state)) # Uncomment\n",
        "            break\n",
        "    \n",
        "    if state.GetResult(state.playerJustMoved) == 1.0:\n",
        "        print(\"Player \" + str(state.playerJustMoved) + \" wins!\")\n",
        "        winner=state.playerJustMoved\n",
        "    elif state.GetResult(state.playerJustMoved) == 0.0:\n",
        "        print(\"Player \" + str(3 - state.playerJustMoved) + \" wins!\")\n",
        "        winner=state.playerJustMoved\n",
        "    else: \n",
        "      print(\"Nobody wins!\")\n",
        "      winner=0\n",
        "\n",
        "    # This list will always have one element less compared to tempdataset because the last state of the game will never have any move associated to it.\n",
        "    # Becasue we are combining the two lists so we want them of equal length hence the move of the last stage will be NaN, \n",
        "    # the last game state will be removed later from the final dataframe.\n",
        "    bestmovelist.append('NaN')  # LINE ADDED.\n",
        "    pjm_list.append('NaN')\n",
        "\n",
        "    for i in range(len(tempdataset)): # LINE ADDED\n",
        "      tempdataset[i].append(pjm_list[i]) #Append the Player at the board state\n",
        "      tempdataset[i].append(bestmovelist[i]) # LINE ADDED. Append the move taken at every stage.\n",
        "    tempdataset\n",
        "    return tempdataset, winner # LINE ADDED.\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\" Play a single game to the end using UCT for both players. \n",
        "    \"\"\"\n",
        "    finaldataset=[] # LINE ADDED. A list os lists of the game stages. Each list is one game, representing the lists of stages returned.\n",
        "    finaldataset1=[] # LINE ADDED. A list of all the stages of the games in the finaldataset. It is the output of converting a list of list into one list.\n",
        "    \n",
        "    p1win=0\n",
        "    p2win=0\n",
        "    Nowin=0\n",
        "    winner=0\n",
        "    for i in range(5000): # LINE ADDED. Run the UCTPlayGame 2000 or 5000 times.\n",
        "      returnds, winner =UCTPlayGame() # LINE EDITED. returnds stores the game temporarily.\n",
        "      finaldataset.append(returnds) # LINE ADDED. \n",
        "      #print(\"Winner : \", winner)\n",
        "      if winner==1:\n",
        "        p1win+=1\n",
        "      elif winner==2:\n",
        "        p2win+=1\n",
        "      else:\n",
        "        Nowin+=1\n",
        "\n",
        "    #Convert list of lists to one list\n",
        "    for i in finaldataset:  # LINE ADDED\n",
        "      for j in i:  # LINE ADDED\n",
        "        finaldataset1.append(j)  # LINE ADDED\n",
        "    \n",
        "    #Name the columns of the finaldataset1 and convert it into a dataframe. # LINE ADDED\n",
        "    datatbp=pd.DataFrame(finaldataset1, columns=['0th pos', '1st pos', '2nd pos', '3rd pos', '4th pos', '5th pos', '6th pos', '7th pos', '8th pos', 'Player','Move'])\n",
        " \n",
        "    #Remove the rows that have 'NaN' as these are the rows depicting the last stage of the game with no move.\n",
        "    datatbp.drop(datatbp[datatbp.Move == 'NaN'].index, inplace=True)\n",
        "    datatbp.reset_index(drop=True, inplace=True) # LINE ADDED. Reset the row index of the data frame\n",
        "    #print(datatbp)\n",
        "    print(\"Wins : \\n Player1 : \", p1win, \" Player2 : \", p2win, \" Nobody wins : \", Nowin)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERY4Jf5xn0UZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''#Download the Dataset to be processed in Assignment 2\n",
        "#2000*10= 20000; 20000-2000=18000 rows if nobody wins for all games.\n",
        "from google.colab import files\n",
        "datatbp.to_csv('CE888_DataToBeProcessed_1900690_biased.csv')\n",
        "files.download('CE888_DataToBeProcessed_1900690_biased.csv')'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OJh-NQRn5u6",
        "colab_type": "text"
      },
      "source": [
        "#Various Research Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyBAUj1uWp07",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "100:100, 100 games, 100 atsets, biased 3, biased for player 2, 5000 games"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCZAWua3MX4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# biased 1 data, 100 games 100 datsets 10:10, 70:30\n",
        "maximum accuracy :  0.47787149849005517\n",
        "depth of decision tree is :  13\n",
        "Wins : \n",
        " DT10 :  4  Other DTs :  4  No wins :  1\n",
        "Wins : \n",
        " DT10 :  4  Other DTs :  5  No wins :  0\n",
        "Wins : \n",
        " DT10 :  3  Other DTs :  4  No wins :  2\n",
        "Wins : \n",
        " DT10 :  4  Other DTs :  3  No wins :  2\n",
        "Wins : \n",
        " DT10 :  5  Other DTs :  1  No wins :  3\n",
        "Wins : \n",
        " DT10 :  6  Other DTs :  0  No wins :  3\n",
        "Wins : \n",
        " DT10 :  9  Other DTs :  0  No wins :  0\n",
        "Wins : \n",
        " DT10 :  5  Other DTs :  2  No wins :  2\n",
        "Wins : \n",
        " DT10 :  4  Other DTs :  3  No wins :  2\n",
        "Wins : \n",
        " DT10 :  4  Other DTs :  3  No wins :  2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWsddo3hJZmc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data provided with player of 5000 games, 50 games, 100 datasets 10:10\n",
        "maximum accuracy :  0.46525490196078434\n",
        "depth of decision tree is :  10\n",
        "Wins : \n",
        " DT10 :  7  Other DTs :  2  No wins :  0\n",
        "Wins : \n",
        " DT10 :  8  Other DTs :  0  No wins :  1\n",
        "Wins : \n",
        " DT10 :  6  Other DTs :  2  No wins :  1\n",
        "Wins : \n",
        " DT10 :  6  Other DTs :  2  No wins :  1\n",
        "Wins : \n",
        " DT10 :  6  Other DTs :  3  No wins :  0\n",
        "Wins : \n",
        " DT10 :  4  Other DTs :  3  No wins :  2\n",
        "Wins : \n",
        " DT10 :  7  Other DTs :  2  No wins :  0\n",
        "Wins : \n",
        " DT10 :  4  Other DTs :  4  No wins :  1\n",
        "Wins : \n",
        " DT10 :  7  Other DTs :  1  No wins :  1\n",
        "Wins : \n",
        " DT10 :  5  Other DTs :  2  No wins :  2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0HVwT_7jwwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#100:100, 300 games, 200 datsets - no file given\n",
        "'''maximum accuracy :  0.603448275862069\n",
        "depth of decision tree is :  13\n",
        "Wins : \n",
        " DT10 :  3  Other DTs :  1  No wins :  5\n",
        "Wins : \n",
        " DT10 :  5  Other DTs :  0  No wins :  4\n",
        "Wins : \n",
        " DT10 :  3  Other DTs :  0  No wins :  6\n",
        "Wins : \n",
        " DT10 :  7  Other DTs :  0  No wins :  2\n",
        "Wins : \n",
        " DT10 :  6  Other DTs :  0  No wins :  3\n",
        "Wins : \n",
        " DT10 :  1  Other DTs :  2  No wins :  6\n",
        "Wins : \n",
        " DT10 :  6  Other DTs :  1  No wins :  2\n",
        "Wins : \n",
        " DT10 :  3  Other DTs :  0  No wins :  6\n",
        "Wins : \n",
        " DT10 :  4  Other DTs :  0  No wins :  5\n",
        "Wins : \n",
        " DT10 :  7  Other DTs :  1  No wins :  1\n",
        "Wins : \n",
        " DT10 :  4  Other DTs :  3  No wins :  2\n",
        "Wins : \n",
        " DT10 :  6  Other DTs :  0  No wins :  3\n",
        "Wins : \n",
        " DT10 :  4  Other DTs :  1  No wins :  4\n",
        "Wins : \n",
        " DT10 :  4  Other DTs :  1  No wins :  4\n",
        "Wins : \n",
        " DT10 :  4  Other DTs :  0  No wins :  5\n",
        "Wins : \n",
        " DT10 :  3  Other DTs :  1  No wins :  5\n",
        "Wins : \n",
        " DT10 :  6  Other DTs :  0  No wins :  3\n",
        "Wins : \n",
        " DT10 :  4  Other DTs :  3  No wins :  2\n",
        "Wins : \n",
        " DT10 :  6  Other DTs :  1  No wins :  2\n",
        "Wins : \n",
        " DT10 :  5  Other DTs :  3  No wins :  1'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARlwyyBajXZf",
        "colab_type": "code",
        "outputId": "cdbcdcf4-826a-4549-bfa3-2284609f600a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#100:100, 100 games, 50 datsets\n",
        "'''maximum accuracy :  0.7266803840877915\n",
        "depth of decision tree is :  11\n",
        "Wins : \n",
        " DT10 :  5  Other DTs :  0  No wins :  4\n",
        "Wins : \n",
        " DT10 :  7  Other DTs :  0  No wins :  2\n",
        "Wins : \n",
        " DT10 :  6  Other DTs :  2  No wins :  1\n",
        "Wins : \n",
        " DT10 :  2  Other DTs :  1  No wins :  6\n",
        "Wins : \n",
        " DT10 :  3  Other DTs :  0  No wins :  6'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'maximum accuracy :  0.7266803840877915\\ndepth of decision tree is :  11\\nWins : \\n DT10 :  5  Other DTs :  0  No wins :  4\\nWins : \\n DT10 :  7  Other DTs :  0  No wins :  2\\nWins : \\n DT10 :  6  Other DTs :  2  No wins :  1\\nWins : \\n DT10 :  2  Other DTs :  1  No wins :  6\\nWins : \\n DT10 :  3  Other DTs :  0  No wins :  6'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJN3sgfjcROS",
        "colab_type": "code",
        "outputId": "eafa9745-ad1e-43d1-f77c-e13f5c06c2e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#100:100, 300 games, 10 runs 100 datasets\n",
        "'''Please enter the number of games to be played : 100\n",
        "Please enter the number of datasets required to be created. Each dataset is a collection of states of a number of OXO games : 100\n",
        "Will you provide the initial datset (Yes=1;No=0) : 1\n",
        "\n",
        "CE888_DataToBeProcessed_1900690_6261Wins.csv(application/vnd.ms-excel) - 1126208 bytes, last modified: 4/12/2020 - 100% done\n",
        "Saving CE888_DataToBeProcessed_1900690_6261Wins.csv to CE888_DataToBeProcessed_1900690_6261Wins (1).csv\n",
        "Enter file name with extention and np path : CE888_DataToBeProcessed_1900690_6261Wins.csv\n",
        "\n",
        "maximum accuracy :  0.7266803840877915\n",
        "depth of decision tree is :  11\n",
        "Wins : \n",
        " DT10 :  4  Other DTs :  0  No wins :  5\n",
        "Wins : \n",
        " DT10 :  6  Other DTs :  0  No wins :  3\n",
        "Wins : \n",
        " DT10 :  5  Other DTs :  0  No wins :  4\n",
        "Wins : \n",
        " DT10 :  7  Other DTs :  0  No wins :  2\n",
        "Wins : \n",
        " DT10 :  5  Other DTs :  1  No wins :  3\n",
        "Wins : \n",
        " DT10 :  3  Other DTs :  0  No wins :  6\n",
        "Wins : \n",
        " DT10 :  2  Other DTs :  1  No wins :  6\n",
        "Wins : \n",
        " DT10 :  5  Other DTs :  0  No wins :  4\n",
        "Wins : \n",
        " DT10 :  3  Other DTs :  0  No wins :  6\n",
        "Wins : \n",
        " DT10 :  4  Other DTs :  0  No wins :  5'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Please enter the number of games to be played : 100\\nPlease enter the number of datasets required to be created. Each dataset is a collection of states of a number of OXO games : 100\\nWill you provide the initial datset (Yes=1;No=0) : 1\\n\\nCE888_DataToBeProcessed_1900690_6261Wins.csv(application/vnd.ms-excel) - 1126208 bytes, last modified: 4/12/2020 - 100% done\\nSaving CE888_DataToBeProcessed_1900690_6261Wins.csv to CE888_DataToBeProcessed_1900690_6261Wins (1).csv\\nEnter file name with extention and np path : CE888_DataToBeProcessed_1900690_6261Wins.csv\\n\\nmaximum accuracy :  0.7266803840877915\\ndepth of decision tree is :  11\\nWins : \\n DT10 :  4  Other DTs :  0  No wins :  5\\nWins : \\n DT10 :  6  Other DTs :  0  No wins :  3\\nWins : \\n DT10 :  5  Other DTs :  0  No wins :  4\\nWins : \\n DT10 :  7  Other DTs :  0  No wins :  2\\nWins : \\n DT10 :  5  Other DTs :  1  No wins :  3\\nWins : \\n DT10 :  3  Other DTs :  0  No wins :  6\\nWins : \\n DT10 :  2  Other DTs :  1  No wins :  6\\nWins : \\n DT10 :  5  Other DTs :  0  No wins :  4\\nWins : \\n DT10 :  3  Other DTs :  0  No wins :  6\\nWins : \\n DT10 :  4  Other DTs :  0  No wins :  5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rk7mgLtDH8ym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#50 games,\n",
        "'''Please enter the number of games to be played : 50\n",
        "Please enter the number of datasets required to be created. Each dataset is a collection of states of a number of OXO games : 100\n",
        "Length of dictionary :  100\n",
        "Wins : \n",
        " DT10 :  7  Other DTs :  1  No wins :  1\n",
        "Wins : \n",
        " DT10 :  7  Other DTs :  1  No wins :  1\n",
        "Wins : \n",
        " DT10 :  3  Other DTs :  3  No wins :  3\n",
        "Wins : \n",
        " DT10 :  7  Other DTs :  2  No wins :  0\n",
        "Wins : \n",
        " DT10 :  5  Other DTs :  2  No wins :  2\n",
        "Wins : \n",
        " DT10 :  3  Other DTs :  5  No wins :  1\n",
        "Wins : \n",
        " DT10 :  8  Other DTs :  0  No wins :  1\n",
        "Wins : \n",
        " DT10 :  3  Other DTs :  4  No wins :  2\n",
        "Wins : \n",
        " DT10 :  4  Other DTs :  2  No wins :  3\n",
        "Wins : \n",
        " DT10 :  6  Other DTs :  1  No wins :  2'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9kBxXnsgcRt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#50:50,50:50, 1000 games, 10, 10 - same DT classifier depth for every 10 iterations."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-kD98pgbl8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#100;10, 50:50, 200 games, 10,10\n",
        "'''Please enter the number of games to be played between Decision tree Classifiers : 10\n",
        "Please enter the number of decision tree classifiers required for each iteration : 10\n",
        "Wins : \n",
        " DT10 :  6  Other DTs :  2  No wins :  1\n",
        "Wins : \n",
        " DT10 :  3  Other DTs :  3  No wins :  3\n",
        "Wins : \n",
        " DT10 :  4  Other DTs :  0  No wins :  5\n",
        "Wins : \n",
        " DT10 :  5  Other DTs :  0  No wins :  4\n",
        "Wins : \n",
        " DT10 :  6  Other DTs :  1  No wins :  2\n",
        "Wins : \n",
        " DT10 :  4  Other DTs :  1  No wins :  4\n",
        "Wins : \n",
        " DT10 :  5  Other DTs :  1  No wins :  3\n",
        "Wins : \n",
        " DT10 :  4  Other DTs :  0  No wins :  5\n",
        "Wins : \n",
        " DT10 :  3  Other DTs :  1  No wins :  5\n",
        "Wins : \n",
        " DT10 :  3  Other DTs :  2  No wins :  4'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bA4WcK9jxx5v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#100:10, 10:90,200 games, 10,10 \n",
        "'''Please enter the number of games to be played between Decision tree Classifiers : 10\n",
        "Please enter the number of decision tree classifiers required for each iteration : 10\n",
        "Wins : \n",
        " DT10 :  7  Other DTs :  2  No wins :  0\n",
        "Wins : \n",
        " DT10 :  6  Other DTs :  2  No wins :  1\n",
        "Wins : \n",
        " DT10 :  6  Other DTs :  2  No wins :  1\n",
        "Wins : \n",
        " DT10 :  6  Other DTs :  1  No wins :  2\n",
        "Wins : \n",
        " DT10 :  8  Other DTs :  0  No wins :  1\n",
        "Wins : \n",
        " DT10 :  6  Other DTs :  1  No wins :  2\n",
        "Wins : \n",
        " DT10 :  8  Other DTs :  0  No wins :  1\n",
        "Wins : \n",
        " DT10 :  4  Other DTs :  1  No wins :  4\n",
        "Wins : \n",
        " DT10 :  8  Other DTs :  0  No wins :  1\n",
        "Wins : \n",
        " DT10 :  8  Other DTs :  0  No wins :  1'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdOnGd5smCtO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#50:50,10:90 200 games, 10,10\n",
        "'''Please enter the number of games to be played between Decision tree Classifiers : 10\n",
        "Please enter the number of decision tree classifiers required for each iteration : 10\n",
        "Wins : \n",
        " DT10 :  7  Other DTs :  1  No wins :  1\n",
        "Wins : \n",
        " DT10 :  7  Other DTs :  2  No wins :  0\n",
        "Wins : \n",
        " DT10 :  8  Other DTs :  1  No wins :  0\n",
        "Wins : \n",
        " DT10 :  8  Other DTs :  0  No wins :  1\n",
        "Wins : \n",
        " DT10 :  5  Other DTs :  1  No wins :  3\n",
        "Wins : \n",
        " DT10 :  8  Other DTs :  0  No wins :  1\n",
        "Wins : \n",
        " DT10 :  7  Other DTs :  1  No wins :  1\n",
        "Wins : \n",
        " DT10 :  7  Other DTs :  2  No wins :  0\n",
        "Wins : \n",
        " DT10 :  6  Other DTs :  3  No wins :  0\n",
        "Wins : \n",
        " DT10 :  5  Other DTs :  0  No wins :  4'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6n6UJtI0l1gR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#10:20,500,10,10\n",
        "'''Please enter the number of games to be played between Decision tree Classifiers : 10\n",
        "Please enter the number of decision tree classifiers required for each iteration : 10\n",
        "Wins : \n",
        " DT10 :  6  Other DTs :  1  No wins :  2\n",
        "Wins : \n",
        " DT10 :  4  Other DTs :  1  No wins :  4\n",
        "Wins : \n",
        " DT10 :  5  Other DTs :  2  No wins :  2\n",
        "Wins : \n",
        " DT10 :  6  Other DTs :  1  No wins :  2\n",
        "Wins : \n",
        " DT10 :  8  Other DTs :  0  No wins :  1\n",
        "Wins : \n",
        " DT10 :  4  Other DTs :  3  No wins :  2\n",
        "Wins : \n",
        " DT10 :  5  Other DTs :  2  No wins :  2\n",
        "Wins : \n",
        " DT10 :  3  Other DTs :  4  No wins :  2\n",
        "Wins : \n",
        " DT10 :  7  Other DTs :  1  No wins :  1\n",
        "Wins : \n",
        " DT10 :  7  Other DTs :  0  No wins :  2'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGShJtTdjzE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#5:500, 2000, 10,10\n",
        "'''Please enter the number of games to be played between Decision tree Classifiers : 10\n",
        "Please enter the number of decision tree classifiers required for each iteration : 10\n",
        "Wins : \n",
        " DT10 :  7  Other DTs :  2  No wins :  0\n",
        "Wins : \n",
        " DT10 :  9  Other DTs :  0  No wins :  0\n",
        "Wins : \n",
        " DT10 :  8  Other DTs :  1  No wins :  0\n",
        "Wins : \n",
        " DT10 :  9  Other DTs :  0  No wins :  0\n",
        "Wins : \n",
        " DT10 :  4  Other DTs :  3  No wins :  2'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3v6eh6rnika",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' 10: 1000 ; 2000 runs.\n",
        "Wins : \n",
        " DT10 :  9  Other DTs :  0  No wins :  0\n",
        "Wins : \n",
        " DT10 :  7  Other DTs :  2  No wins :  0\n",
        "Wins : \n",
        " DT10 :  8  Other DTs :  1  No wins :  0\n",
        "Wins : \n",
        " DT10 :  8  Other DTs :  0  No wins :  1\n",
        "Wins : \n",
        " DT10 :  8  Other DTs :  1  No wins :  0\n",
        "Wins : \n",
        " DT10 :  7  Other DTs :  2  No wins :  0\n",
        "Wins : \n",
        " DT10 :  6  Other DTs :  3  No wins :  0\n",
        "Wins : \n",
        " DT10 :  7  Other DTs :  2  No wins :  0\n",
        " '''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTMhMMpFMhLo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Download the Dataset to be processed in Assignment 2\n",
        "#2000*10= 20000; 20000-2000=18000 rows if nobody wins for all games.\n",
        "#from google.colab import files\n",
        "#datatbp.to_csv('CE888_DataToBeProcessed_1900690.csv')\n",
        "#files.download('CE888_DataToBeProcessed_1900690.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nt6ny6ZKg93-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''import os\n",
        "print(os.getcwd())'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QIVKeKsgCd6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''#Get data set from Drive\n",
        "Data=pd.read_csv('CE888_DataToBeProcessed_1900690_6261Wins.csv')\n",
        "Data'''"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}