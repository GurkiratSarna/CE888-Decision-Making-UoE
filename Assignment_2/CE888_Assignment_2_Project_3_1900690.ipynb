{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of CE888 - Project 3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GurkiratSarna/CE888-Decision-Making-UoE/blob/master/Assignment_2/CE888_Assignment_2_Project_3_1900690.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB3yAuxfqgRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import tree\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt #plotting charts\n",
        "import pandas as pd #helps importing datasets\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from math import *\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDPxCw_O9huO",
        "colab_type": "text"
      },
      "source": [
        "#Create Decision Tree classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vjh-DntU1lXI",
        "colab_type": "text"
      },
      "source": [
        "create_DT_classifier() function takes as input the complete dataset of 2000 games and trains a Decision tree on it to return the classifier. \n",
        "\n",
        "The input data set is split into 70-30 percent for training and testing. A graph is plotted between accuracy and depth of the tree for 40 iterations. From this graph the depth of the tree which gives highest accuracy is used to train the classifiers for the complete project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSbikEdknrF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_DT_classifier(Data_in,f_run, depth_max_accuracy):\n",
        "    #Split data into 70-30 percent for training and testing\n",
        "    train_set, test_set = train_test_split(Data_in, test_size = 0.3, random_state=42)\n",
        "    \n",
        "    #Only take the features for training - 9 positions of the board\n",
        "    Data_train_x=train_set.iloc[:,0:9]\n",
        "    \n",
        "    #the output column extracted from the data for training\n",
        "    Data_train_y=train_set.iloc[:,-1]\n",
        "    Data_train_y=Data_train_y.astype('int')\n",
        "    \n",
        "    #Only take the features for testin - 9 positions of the board\n",
        "    Data_test_x=test_set.iloc[:,0:9]\n",
        "    \n",
        "    #the output column extracted from the data for testing\n",
        "    Data_test_y=test_set.iloc[:,-1]\n",
        "    Data_test_y=Data_test_y.astype('int')\n",
        "\n",
        "    ########################\n",
        "    #Plotting graph for accuracy against the depth of the decision tree ranging from 0 to 39 (inclusive)\n",
        "    if(f_run==1):\n",
        "      depth_range = list(range(1,40))\n",
        "      accuracy_list = []\n",
        "      for depth in depth_range:\n",
        "        classifier_DT1 = DecisionTreeClassifier(criterion='gini',max_depth=depth,random_state=42)\n",
        "        classifier_DT1.fit(Data_train_x, Data_train_y)\n",
        "        score = classifier_DT1.score(Data_test_x, Data_test_y)\n",
        "        accuracy_list.append(score)\n",
        "      plt.plot(depth_range,accuracy_list) # commented to save space for output\n",
        "      plt.show()  # commented to save space for output\n",
        "      #Pick the depth at which accuracy is maximum only during the first run and train the classifier on that depth for the complete project.\n",
        "      depth_max_accuracy =(accuracy_list.index(max(accuracy_list)) + 1)\n",
        "      print(\"maximum accuracy : \", max(accuracy_list))\n",
        "      print(\"depth of tree at the maimum accuracy : \", depth_max_accuracy)\n",
        "    #########################\n",
        "    \n",
        "    \n",
        "    #Train the classifier on the max accuracy in every iteration\n",
        "    classifier_DT = DecisionTreeClassifier(criterion='gini',max_depth=depth_max_accuracy,random_state=42)\n",
        "    classifier_DT.fit(Data_train_x, Data_train_y)\n",
        "    Pred_test_y=classifier_DT.predict(Data_test_x)\n",
        "    #print(classification_report(Data_test_y,Pred_test_y)) #Need not print for Assignment 2 also commented to save space for output\n",
        "\n",
        "    return classifier_DT, depth_max_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46iTScHP9n0Q",
        "colab_type": "text"
      },
      "source": [
        "#OXO Game\n",
        "The OXO game creates a dataset of 100 games."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTTExuwIPSQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is a very simple implementation of the UCT Monte Carlo Tree Search algorithm in Python 2.7.\n",
        "# The function UCT(rootstate, itermax, verbose = False) is towards the bottom of the code.\n",
        "# It aims to have the clearest and simplest possible code, and for the sake of clarity, the code\n",
        "# is orders of magnitude less efficient than it could be made, particularly by using a \n",
        "# state.GetRandomMove() or state.DoRandomRollout() function.\n",
        "# \n",
        "# Example GameState classes for Nim, OXO and Othello are included to give some idea of how you\n",
        "# can write your own GameState use UCT in your 2-player game. Change the game to be played in \n",
        "# the UCTPlayGame() function at the bottom of the code.\n",
        "# \n",
        "# Written by Peter Cowling, Ed Powley, Daniel Whitehouse (University of York, UK) September 2012.\n",
        "# \n",
        "# Licence is granted to freely use and distribute for any sensible/legal purpose so long as this comment\n",
        "# remains in any distributed code.\n",
        "# \n",
        "class OXOState:\n",
        "    \"\"\" A state of the game, i.e. the game board.\n",
        "        Squares in the board are in this arrangement\n",
        "        012\n",
        "        345\n",
        "        678\n",
        "        where 0 = empty, 1 = player 1 (X), 2 = player 2 (O)\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.playerJustMoved = 2 # At the root pretend the player just moved is 2 whereas player 1 has the first move.\n",
        "        self.board = [0,0,0,0,0,0,0,0,0] # 0 = empty, 1 = player 1, 2 = player 2. This is the initial board state - all positions are empty.\n",
        "        \n",
        "    def Clone(self):\n",
        "        \"\"\" Create a deep clone of this game state.\n",
        "        \"\"\"\n",
        "        st = OXOState()\n",
        "        st.playerJustMoved = self.playerJustMoved\n",
        "        st.board = self.board[:]\n",
        "        return st\n",
        "\n",
        "    def DoMove(self, move):\n",
        "        \"\"\" Update the state board by replacing 0 with the player playing the move at the position/move of the board.\n",
        "            Must update playerJustMoved.\n",
        "        \"\"\"\n",
        "        assert move >= 0 and move <= 8 and move == int(move) and self.board[move] == 0\n",
        "        self.playerJustMoved = 3 - self.playerJustMoved\n",
        "        self.board[move] = self.playerJustMoved\n",
        "        \n",
        "    def GetMoves(self):\n",
        "        \"\"\" Get all possible moves from this state. That is return all the positional values of the zroes in the state board.\n",
        "        \"\"\"\n",
        "        return [i for i in range(9) if self.board[i] == 0]\n",
        "    \n",
        "    def GetResult(self, playerjm):\n",
        "        \"\"\" Get the game result from the viewpoint of playerjm. \n",
        "        \"\"\"\n",
        "        for (x,y,z) in [(0,1,2),(3,4,5),(6,7,8),(0,3,6),(1,4,7),(2,5,8),(0,4,8),(2,4,6)]:\n",
        "            #Winning possibilities of the board\n",
        "            if self.board[x] == self.board[y] == self.board[z]: # check if values in all the 3 positions is of the same player\n",
        "                # check if the player that just moved is same as the value in the winning positions, if yes return 1 else 0 stating that the other player wins.\n",
        "                if self.board[x] == playerjm: \n",
        "                    return 1.0\n",
        "                else:\n",
        "                    return 0.0\n",
        "        if self.GetMoves() == []:\n",
        "          return 0.5 # draw\n",
        "        return False # Should not be possible to get here\n",
        "\n",
        "    def __repr__(self): # This is how the return value is defined for this class.\n",
        "        s= \"\"\n",
        "        for i in range(9): \n",
        "            s += \".XO\"[self.board[i]] # . for 0, X for 1 and O for 2 positional values\n",
        "            if i % 3 == 2: s += \"\\n\"\n",
        "        return s\n",
        "\n",
        "\n",
        "class Node:\n",
        "    \"\"\" A node in the game tree. Note : wins is always from the viewpoint of playerJustMoved.\n",
        "        Crashes if state not specified.\n",
        "    \"\"\"\n",
        "    def __init__(self, move = None, parent = None, state = None):\n",
        "        self.move = move # the move that got us to this node - \"None\" for the root node\n",
        "        #parentNode stores all the parents from the rootnode until the current node for backpropogation, during which it deletes until it is None.\n",
        "        self.parentNode = parent # \"None\" for the root node.\n",
        "        self.childNodes = []\n",
        "        self.wins = 0\n",
        "        self.visits = 0 #The number of itermax passed\n",
        "        self.untriedMoves = state.GetMoves() # future child nodes. The available positions to be played at any point of the game.\n",
        "        self.playerJustMoved = state.playerJustMoved # the only part of the state that the Node needs later\n",
        "        \n",
        "    def UCTSelectChild(self):\n",
        "        \"\"\" Use the UCB1 formula to select a child node. Often a constant UCTK is applied so we have\n",
        "            lambda c: c.wins/c.visits + UCTK * sqrt(2*log(self.visits)/c.visits to vary the amount of\n",
        "            exploration versus exploitation.\n",
        "        \"\"\"\n",
        "        s = sorted(self.childNodes, key = lambda c: c.wins/c.visits + sqrt(2*log(self.visits)/c.visits))[-1] #pick the highest\n",
        "        return s\n",
        "    \n",
        "    def AddChild(self, m, s):\n",
        "        \"\"\" Remove m from untriedMoves and add a new child node for this move.\n",
        "            Return the added child node.\n",
        "        \"\"\"\n",
        "        n = Node(move = m, parent = self, state = s)\n",
        "        self.untriedMoves.remove(m)\n",
        "        self.childNodes.append(n)\n",
        "        return n\n",
        "    \n",
        "    def Update(self, result):\n",
        "        \"\"\" Update this node - one additional visit and result additional wins. result must be from the viewpoint of playerJustmoved.\n",
        "        \"\"\"\n",
        "        self.visits += 1\n",
        "        self.wins += result\n",
        "\n",
        "    def __repr__(self): # Added other variables to be returned to check the flow of the variable during testing small iterations.\n",
        "        return \"[M:\" + str(self.move) + \" W/V:\" + str(self.wins) + \"/\" + str(self.visits) + \" U:\" + str(self.untriedMoves) + \" PJM:\" + str(self.playerJustMoved) + \"]\"\n",
        "\n",
        "    def TreeToString(self, indent):\n",
        "        s = self.IndentString(indent) + str(self)\n",
        "        for c in self.childNodes:\n",
        "             s += c.TreeToString(indent+1)\n",
        "        return s\n",
        "\n",
        "    def IndentString(self,indent):\n",
        "        s = \"\\n\"\n",
        "        for i in range (1,indent+1):\n",
        "            s += \"| \"\n",
        "        return s\n",
        "\n",
        "    def ChildrenToString(self):\n",
        "        s = \"\"\n",
        "        for c in self.childNodes:\n",
        "             s += str(c) + \"\\n\"\n",
        "        return s\n",
        "\n",
        "def GetRandomMove(s,c_dt):\n",
        "    \"\"\"We will pick a random value between 0.0 and 1.0. Considering there is a normal distribution between these values, \n",
        "       if we get a value between 0.0 and 0.9 then the decision tree classifier decides the next move on the given state otherwise a random integer is returned.\n",
        "    \"\"\"\n",
        "    \n",
        "    rand_num=random.uniform(0.0, 1.0)\n",
        "\n",
        "    if rand_num <= 0.9:\n",
        "        next_move=c_dt.predict([s.board])\n",
        "        next_move=next_move[0]\n",
        "    \n",
        "        #If the move decided by decision tree classifier is not in the untried moves then we select randomly the next eligible move.\n",
        "        if next_move not in s.GetMoves():\n",
        "            next_move=random.choice(s.GetMoves())\n",
        "            \"\"\"Add the move taken at this state to a global list 'train_state'.\n",
        "               These are unexepected states that will be combined with the dataset, containing 2000 game states, to train the model in next iteration.\n",
        "            \"\"\"\n",
        "            st_board=list(s.board) #so that it does not point to the same memory address\n",
        "            st_board.append(next_move) # append the random move at this state\n",
        "            train_state.append(st_board)            \n",
        "    else:\n",
        "        next_move=random.choice(s.GetMoves())\n",
        "    return next_move\n",
        "    \n",
        "def UCT(firstrun, classifier_dt, rootstate, itermax, verbose = False):\n",
        "    \"\"\" Conduct a UCT search for itermax iterations starting from rootstate.\n",
        "        Return the best move from the rootstate.\n",
        "        Assumes 2 alternating players (player 1 starts), with game results in the range [0.0, 1.0].\"\"\"\n",
        "\n",
        "    rootnode = Node(state = rootstate)\n",
        "\n",
        "    for i in range(itermax):\n",
        "        node = rootnode\n",
        "        state = rootstate.Clone()\n",
        "\n",
        "        # Select\n",
        "        while node.untriedMoves == [] and node.childNodes != []: # node is fully expanded and non-terminal\n",
        "            node = node.UCTSelectChild()\n",
        "            state.DoMove(node.move)\n",
        "\n",
        "        # Expand\n",
        "        if node.untriedMoves != []:  # if we can expand (i.e. state/node is non-terminal)\n",
        "            m = random.choice(node.untriedMoves) # this m has to be picked by the DT train 90% times and 10% randomly.\n",
        "            state.DoMove(m)\n",
        "            node = node.AddChild(m, state)  # add child and descend tree. This updates the parent node as well.\n",
        "\n",
        "        # Rollout\n",
        "        '''Game is played considering all eligible moves after the move chosen in Expand step.\n",
        "        In every step of this game, a child node and parent node is added to form a tree. Once all possible branches are created the best move is returned\n",
        "        using the UCB1 formula in UCTSelectChild() function.'''\n",
        "        while state.GetMoves() != []: # while state is non-terminal\n",
        "            if firstrun==1: # if the code is executed from the scratch and no initial input file of states is given.\n",
        "                r=random.choice(state.GetMoves())\n",
        "            else:\n",
        "                r=GetRandomMove(state, classifier_dt)\n",
        "            state.DoMove(r)\n",
        "        \n",
        "        # Backpropagate\n",
        "        while node != None: # backpropagate from the expanded node and work back to the root node\n",
        "            gr=state.GetResult(node.playerJustMoved)\n",
        "            node.Update(gr) # state is terminal. Update node with result from POV of node.playerJustMoved\n",
        "            node = node.parentNode\n",
        "\n",
        "    # Output some information about the tree - Commented to save space for the output\n",
        "    #if verbose: print(rootnode.TreeToString(0))\n",
        "    #else: print(rootnode.ChildrenToString())\n",
        "    \n",
        "    ret=sorted(rootnode.childNodes, key = lambda c: c.visits)[-1].move\n",
        "\n",
        "    return ret # return the move that was most visited as the best move.\n",
        "                \n",
        "def UCTPlayGame(firstrun, classifier_dt): #These simulations are MCTS\n",
        "    \"\"\" Play a sample game between two UCT players where each player gets a different number \n",
        "        of UCT iterations (= simulations = tree nodes).\n",
        "    \"\"\"\n",
        "    state = OXOState()\n",
        "\n",
        "    tempdataset=[[0,0,0,0,0,0,0,0,0]] #  A temporary datset which will accumulate all the stages of one game\n",
        "    # A list of best moves for that particular game. This will always have length of tempdataset-1 because of the initial stage in the temporary dataset.\n",
        "    bestmovelist=[] #\n",
        "    while state.GetMoves() != []:\n",
        "        #print(str(state)) # prints the board. Commented to save the space for output visibility.\n",
        "        \n",
        "        '''We introduce bias towards player 1 because we associate player 1 to the most learnt Decision Tree (later).\n",
        "        The bias is introduced by increasing the itermax value in 'else' as compared to itermax value in 'if' for player 2'''\n",
        "        '''For assignment 2, we remove the bias to have a fair play between both the players and to ralise the learning'''\n",
        "        '''1000:2000 -> No one wins; 1500:2000 -> No one wins; 10:1000 -> nearly 2.5% winning - Assignment 1\n",
        "        10:1000 -> with 5000 iterations of UCTPlaygame -> 12.5% winning games - Assignment 1'''\n",
        "        if state.playerJustMoved == 1: #The consition checks for player 1 but the best move is returned for player 2.\n",
        "            m = UCT(firstrun, classifier_dt, rootstate=state, itermax=100, verbose=False)  # play with values for itermax and verbose = True.\n",
        "        else:\n",
        "            m = UCT(firstrun, classifier_dt, rootstate=state, itermax=100, verbose=False) # itermax decides the total value of visits to one node in a given game.\n",
        "        #print(\"Best Move: \" + str(m) + \"\\n\") # Commented to save space for the output\n",
        "        state.DoMove(m)\n",
        "        \n",
        "        bestmovelist.append(m)\n",
        "        tempdataset.append(list(state.board))\n",
        "        \n",
        "        if state.GetResult(state.playerJustMoved) != False:\n",
        "            #print(str(state)) # Commented to save space for the output\n",
        "            break\n",
        "    \n",
        "    if state.GetResult(state.playerJustMoved) == 1.0:\n",
        "        #print(\"Player \" + str(state.playerJustMoved) + \" wins!\") #Commented to save space for the output\n",
        "        winner=state.playerJustMoved\n",
        "    elif state.GetResult(state.playerJustMoved) == 0.0:\n",
        "        #print(\"Player \" + str(3 - state.playerJustMoved) + \" wins!\") #Commented to save space for the output\n",
        "        winner=(3-state.playerJustMoved)\n",
        "    else: \n",
        "      #print(\"Nobody wins!\") #Commented to save space for the output\n",
        "      winner=0\n",
        "\n",
        "    ''' This list will always have one element less compared to tempdataset because the last state of the game will never have any move associated to it.\n",
        "    Because we are combining the two lists so we want them of equal length hence the move of the last stage will be NaN, \n",
        "    the last game state will be removed later from the final dataframe.'''\n",
        "    bestmovelist.append('NaN')\n",
        "    \n",
        "    for i in range(len(tempdataset)): \n",
        "      tempdataset[i].append(bestmovelist[i]) # Append the move taken at every stage.\n",
        "\n",
        "    return tempdataset, winner \n",
        "\n",
        "def create_OXO_dataset(num_games, firstrun, classifier_dt):\n",
        "    \"\"\" Play a single game to the end using UCT for both players. \n",
        "    \"\"\"\n",
        "    finaldataset=[] # A list of lists of the game stages. Each list is one game, representing the lists of stages returned.\n",
        "    finaldataset1=[] # A list of all the stages of the games in the finaldataset. It is the output of converting a list of list into one list.\n",
        "    \n",
        "    p1win=0\n",
        "    p2win=0\n",
        "    Nowin=0\n",
        "    winner=0\n",
        "    for i in range(num_games): # Run the UCTPlayGame 2000 times.\n",
        "      returnds, winner =UCTPlayGame(firstrun, classifier_dt) # returnds stores the game temporarily.\n",
        "      finaldataset.append(returnds) \n",
        "      if winner==1:\n",
        "        p1win+=1\n",
        "      elif winner==2:\n",
        "        p2win+=1\n",
        "      else:\n",
        "        Nowin+=1\n",
        "\n",
        "    #Convert list of lists to one list\n",
        "    for i in finaldataset:  \n",
        "      for j in i:  \n",
        "        finaldataset1.append(j) \n",
        "\n",
        "    #Name the columns of the finaldataset1 and convert it into a dataframe.\n",
        "    datatbp=pd.DataFrame(finaldataset1, columns=['0th pos', '1st pos', '2nd pos', '3rd pos', '4th pos', '5th pos', '6th pos', '7th pos', '8th pos', 'Move'])\n",
        "     \n",
        "    #Remove the rows that have 'NaN' as these are the rows depicting the last stage of the game with no move.\n",
        "    datatbp.drop(datatbp[datatbp.Move == 'NaN'].index, inplace=True)\n",
        "    datatbp.reset_index(drop=True, inplace=True) #  Reset the row index of the data frame\n",
        "\n",
        "    #print(\"Wins : Player1 : \", p1win, \" Player2 : \", p2win, \" Nobody wins : \", Nowin) #Commented to save space for the output\n",
        "    \n",
        "    return datatbp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OxFMCsF96xe",
        "colab_type": "text"
      },
      "source": [
        "#Classifiers collection\n",
        "create_classifier_dict() function creates the dictionary of classifiers for each datset of 2000 games played. The num_classifier is a value for the number of classifiers (number of datsets of 2000 games each) needed in a dictionary in one iteration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKUDFU5ZbxLX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_classifier_dict(num_classifier):\n",
        "   \"\"\"firstrun is a flag depicting if the code is going to create a dataset of 2000 games for the first time or not. \n",
        "      1 means it is a first run and 0 means it is not.\n",
        "   \"\"\"\n",
        "   firstrun=1\n",
        "   dict_classifier={}\n",
        "   depth_max=0\n",
        "   classifier=None\n",
        "   for i in range(num_classifier):\n",
        "       data_tbp=create_OXO_dataset(1000,firstrun, classifier) # Is this imitation learning that includes the apprentice policy and expert policy creation ?\n",
        "       \n",
        "       comb_train_state=pd.DataFrame(train_state,columns=['0th pos', '1st pos', '2nd pos', '3rd pos', '4th pos', '5th pos', '6th pos', '7th pos', '8th pos', 'Move'])\n",
        "       data_tbp=pd.concat([data_tbp,comb_train_state],ignore_index=True, axis=0)\n",
        "       \n",
        "       #combine the data_tbp and train_state here and then create a classifier\n",
        "       classifier, depth_max=create_DT_classifier(data_tbp, firstrun, depth_max)\n",
        "       print('depth_max : ', depth_max)\n",
        "       dict_classifier.update({i:classifier})\n",
        "\n",
        "       firstrun=0\n",
        "       train_state.clear()\n",
        "   return dict_classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFtC8DKlpo_N",
        "colab_type": "text"
      },
      "source": [
        "#OXO Game for Classifiers\n",
        "Below is a modified version of OXO game to have the classifiers play against each other. The class Node and OXOstate have not been redefined. We associate player 1 with every 10th classifier and player 2 with it's previous 9 versions of the classifier. That is tenth DT classifier (DT10) will play against first DT classifier (DT1) then with DT2 and so on until DT9. After every iteration we calculate the number of times DT10 wins against DT1, DT2...DT9. Player 1 always plays with DT10 decisions and player 2 plays with DT1, DT2...DT9 decisions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3rhKXTSFdnL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def GetRandomMove1(DTclassifier, s):\n",
        "    r=DTclassifier.predict([s.board])\n",
        "    r=r[0]\n",
        "    if r not in s.GetMoves():\n",
        "        r=random.choice(s.GetMoves())\n",
        "    return r\n",
        "\n",
        "def UCT1(pl1_classifier, pl2_classifier,rootstate, itermax, verbose = False):\n",
        "    \"\"\" Conduct a UCT search for itermax iterations starting from rootstate.\n",
        "        Return the best move from the rootstate.\n",
        "        Assumes 2 alternating players (player 1 starts), with game results in the range [0.0, 1.0].\"\"\"\n",
        "\n",
        "    rootnode = Node(state = rootstate)\n",
        "\n",
        "    for i in range(itermax):\n",
        "        node = rootnode\n",
        "        state = rootstate.Clone()\n",
        "\n",
        "        # Select\n",
        "        while node.untriedMoves == [] and node.childNodes != []: # node is fully expanded and non-terminal\n",
        "            node = node.UCTSelectChild()\n",
        "            state.DoMove(node.move)\n",
        "\n",
        "        # Expand\n",
        "        if node.untriedMoves != []: # if we can expand (i.e. state/node is non-terminal)\n",
        "            #Do we have to guess using pl1classifier ?\n",
        "            #print('In Expand, state.pjm : ', state.playerJustMoved)\n",
        "             #if(state.playerJustMoved==1):\n",
        "            #    m=GetRandomMove1(pl1_classifier,state)\n",
        "            #else:\n",
        "            #    m=GetRandomMove1(pl2_classifier,state)\n",
        "            \n",
        "            m = random.choice(node.untriedMoves)\n",
        "            state.DoMove(m)\n",
        "            node = node.AddChild(m,state) # add child and descend tree\n",
        "\n",
        "        # Rollout \n",
        "        while state.GetMoves() != []: # while state is non-terminal\n",
        "\n",
        "            if(state.playerJustMoved==1):\n",
        "                r=GetRandomMove1(pl1_classifier,state)\n",
        "            else:\n",
        "                r=GetRandomMove1(pl2_classifier,state)\n",
        "            state.DoMove(r)\n",
        "\n",
        "        # Backpropagate\n",
        "        while node != None: # backpropagate from the expanded node and work back to the root node\n",
        "            node.Update(state.GetResult(node.playerJustMoved)) # state is terminal. Update node with result from POV of node.playerJustMoved\n",
        "            node = node.parentNode\n",
        "\n",
        "    # Output some information about the tree - Commented to save space for Output\n",
        "    #if (verbose): print(rootnode.TreeToString(0))\n",
        "    #else: print(rootnode.ChildrenToString())\n",
        "\n",
        "    return sorted(rootnode.childNodes, key = lambda c: c.visits)[-1].move # return the move that was most visited\n",
        "                \n",
        "def UCTPlayGame1(pl1_classifier, pl2_classifier):\n",
        "    \"\"\" Play a sample game between two UCT players where each player gets a different number \n",
        "        of UCT iterations (= simulations = tree nodes).\n",
        "    \"\"\"\n",
        "    \n",
        "    state = OXOState() \n",
        "    \n",
        "    while (state.GetMoves() != []):\n",
        "        #print(str(state)) #Commented to save space for Output\n",
        "        if state.playerJustMoved == 1:\n",
        "            m = UCT1(pl1_classifier, pl2_classifier,rootstate = state, itermax = 50, verbose = False) \n",
        "        else:\n",
        "            m = UCT1(pl1_classifier, pl2_classifier, rootstate = state, itermax =50, verbose = False)\n",
        "        #print(\"Best Move: \" + str(m) + \"\\n\") #Commented to save space for Output\n",
        "        state.DoMove(m)\n",
        "        if state.GetResult(state.playerJustMoved) != False:\n",
        "            #print(str(state)) #Commented to save space for Output\n",
        "            break\n",
        "    if state.GetResult(state.playerJustMoved) == 1.0:\n",
        "        #print(\"Player \" + str(state.playerJustMoved) + \" wins!\") #Commented to save space for Output\n",
        "        return state.playerJustMoved\n",
        "    elif state.GetResult(state.playerJustMoved) == 0.0:\n",
        "        #print(\"Player \" + str(3 - state.playerJustMoved) + \" wins!\") #Commented to save space for Output\n",
        "        return (3-state.playerJustMoved)\n",
        "    else:\n",
        "        #print(\"Nobody wins!\") #Commented to save space for Output\n",
        "        return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdjNZQpcqZSu",
        "colab_type": "text"
      },
      "source": [
        "#Classifier Game Play\n",
        "Gameplay_classifiers() function calls the create_classifier_dict() to get a dictionary of classifiers trained on a single dataset of 2000 games. After a single dictionary is received, OXO Game is played between the classifiers by calling UCTPlayGame1() function. The UCTPlayGame1() function is provided with 2 classifers, the first classifier is always the tenth classifier and the second classifier varies from DT1 until DT9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PufVfTNjFL4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Play game between Classifiers.\n",
        "def Gameplay_classifiers(dt_clfr_games, num_dt_clfr):\n",
        "  for i in range(dt_clfr_games):\n",
        "      getdictionary=create_classifier_dict(num_dt_clfr)\n",
        "      DT10=0\n",
        "      DTother=0\n",
        "      Nowin=0\n",
        "      for i in range(len(getdictionary)-1): # execute from 0 until 8th index\n",
        "          winner = UCTPlayGame1(getdictionary[len(getdictionary)-1], getdictionary[i]) # transfer 9 always and every value from 0 to 8\n",
        "          #print(winner)\n",
        "          if winner==1:\n",
        "            #print('DT10 wins')\n",
        "            DT10+=1\n",
        "          elif winner==2:\n",
        "            #print('DT',i+1,' wins')\n",
        "            DTother+=1\n",
        "          else:\n",
        "            #print('No wins')\n",
        "            Nowin+=1\n",
        "      print(\"Wins : \\n DT10 : \", DT10, \" Other DTs : \", DTother, \" No wins : \", Nowin)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qak6MwDoezzr",
        "colab_type": "code",
        "outputId": "bb658e5f-ac39-4d25-bf8d-43147882b774",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        " \n",
        "  # create a global list to record the unexpected states encountered by the Decision tree. These are states for which DT could not give an eligible move.\n",
        "  global train_state \n",
        "  train_state=[]\n",
        "\n",
        "  dt_clfr_games=int(input('Please enter the number of games to be played between Decision tree Classifiers : '))\n",
        "  #print(dt_clfr_games)\n",
        "\n",
        "  dt_clfr=int(input('Please enter the number of decision tree classifiers required for each iteration : '))\n",
        "  #print(dt_clfr)\n",
        "  \n",
        "  Gameplay_classifiers(dt_clfr_games, dt_clfr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please enter the number of games to be played between Decision tree Classifiers : 10\n",
            "Please enter the number of decision tree classifiers required for each iteration : 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "maximum accuracy :  0.6371036846615252\n",
            "depth of tree at the maimum accuracy :  14\n",
            "depth_max :  14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9kBxXnsgcRt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#50:50,50:50, 1000 games, 10, 10 - same DT classifier depth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-kD98pgbl8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#100;10, 50:50, 200 games, 10,10\n",
        "'''Please enter the number of games to be played between Decision tree Classifiers : 10\n",
        "Please enter the number of decision tree classifiers required for each iteration : 10\n",
        "Wins : \n",
        " DT10 :  6  Other DTs :  2  No wins :  1\n",
        "Wins : \n",
        " DT10 :  3  Other DTs :  3  No wins :  3\n",
        "Wins : \n",
        " DT10 :  4  Other DTs :  0  No wins :  5\n",
        "Wins : \n",
        " DT10 :  5  Other DTs :  0  No wins :  4\n",
        "Wins : \n",
        " DT10 :  6  Other DTs :  1  No wins :  2\n",
        "Wins : \n",
        " DT10 :  4  Other DTs :  1  No wins :  4\n",
        "Wins : \n",
        " DT10 :  5  Other DTs :  1  No wins :  3\n",
        "Wins : \n",
        " DT10 :  4  Other DTs :  0  No wins :  5\n",
        "Wins : \n",
        " DT10 :  3  Other DTs :  1  No wins :  5\n",
        "Wins : \n",
        " DT10 :  3  Other DTs :  2  No wins :  4'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bA4WcK9jxx5v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#100:10, 10:90,200 games, 10,10 \n",
        "'''Please enter the number of games to be played between Decision tree Classifiers : 10\n",
        "Please enter the number of decision tree classifiers required for each iteration : 10\n",
        "Wins : \n",
        " DT10 :  7  Other DTs :  2  No wins :  0\n",
        "Wins : \n",
        " DT10 :  6  Other DTs :  2  No wins :  1\n",
        "Wins : \n",
        " DT10 :  6  Other DTs :  2  No wins :  1\n",
        "Wins : \n",
        " DT10 :  6  Other DTs :  1  No wins :  2\n",
        "Wins : \n",
        " DT10 :  8  Other DTs :  0  No wins :  1\n",
        "Wins : \n",
        " DT10 :  6  Other DTs :  1  No wins :  2\n",
        "Wins : \n",
        " DT10 :  8  Other DTs :  0  No wins :  1\n",
        "Wins : \n",
        " DT10 :  4  Other DTs :  1  No wins :  4\n",
        "Wins : \n",
        " DT10 :  8  Other DTs :  0  No wins :  1\n",
        "Wins : \n",
        " DT10 :  8  Other DTs :  0  No wins :  1'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdOnGd5smCtO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#50:50,10:90 200 games, 10,10\n",
        "'''Please enter the number of games to be played between Decision tree Classifiers : 10\n",
        "Please enter the number of decision tree classifiers required for each iteration : 10\n",
        "Wins : \n",
        " DT10 :  7  Other DTs :  1  No wins :  1\n",
        "Wins : \n",
        " DT10 :  7  Other DTs :  2  No wins :  0\n",
        "Wins : \n",
        " DT10 :  8  Other DTs :  1  No wins :  0\n",
        "Wins : \n",
        " DT10 :  8  Other DTs :  0  No wins :  1\n",
        "Wins : \n",
        " DT10 :  5  Other DTs :  1  No wins :  3\n",
        "Wins : \n",
        " DT10 :  8  Other DTs :  0  No wins :  1\n",
        "Wins : \n",
        " DT10 :  7  Other DTs :  1  No wins :  1\n",
        "Wins : \n",
        " DT10 :  7  Other DTs :  2  No wins :  0\n",
        "Wins : \n",
        " DT10 :  6  Other DTs :  3  No wins :  0\n",
        "Wins : \n",
        " DT10 :  5  Other DTs :  0  No wins :  4'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6n6UJtI0l1gR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#10:20,500,10,10\n",
        "'''Please enter the number of games to be played between Decision tree Classifiers : 10\n",
        "Please enter the number of decision tree classifiers required for each iteration : 10\n",
        "Wins : \n",
        " DT10 :  6  Other DTs :  1  No wins :  2\n",
        "Wins : \n",
        " DT10 :  4  Other DTs :  1  No wins :  4\n",
        "Wins : \n",
        " DT10 :  5  Other DTs :  2  No wins :  2\n",
        "Wins : \n",
        " DT10 :  6  Other DTs :  1  No wins :  2\n",
        "Wins : \n",
        " DT10 :  8  Other DTs :  0  No wins :  1\n",
        "Wins : \n",
        " DT10 :  4  Other DTs :  3  No wins :  2\n",
        "Wins : \n",
        " DT10 :  5  Other DTs :  2  No wins :  2\n",
        "Wins : \n",
        " DT10 :  3  Other DTs :  4  No wins :  2\n",
        "Wins : \n",
        " DT10 :  7  Other DTs :  1  No wins :  1\n",
        "Wins : \n",
        " DT10 :  7  Other DTs :  0  No wins :  2'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGShJtTdjzE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#5:500, 2000, 10,10\n",
        "'''Please enter the number of games to be played between Decision tree Classifiers : 10\n",
        "Please enter the number of decision tree classifiers required for each iteration : 10\n",
        "Wins : \n",
        " DT10 :  7  Other DTs :  2  No wins :  0\n",
        "Wins : \n",
        " DT10 :  9  Other DTs :  0  No wins :  0\n",
        "Wins : \n",
        " DT10 :  8  Other DTs :  1  No wins :  0\n",
        "Wins : \n",
        " DT10 :  9  Other DTs :  0  No wins :  0\n",
        "Wins : \n",
        " DT10 :  4  Other DTs :  3  No wins :  2'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3v6eh6rnika",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' 10: 1000 ; 2000 runs.\n",
        "Wins : \n",
        " DT10 :  9  Other DTs :  0  No wins :  0\n",
        "Wins : \n",
        " DT10 :  7  Other DTs :  2  No wins :  0\n",
        "Wins : \n",
        " DT10 :  8  Other DTs :  1  No wins :  0\n",
        "Wins : \n",
        " DT10 :  8  Other DTs :  0  No wins :  1\n",
        "Wins : \n",
        " DT10 :  8  Other DTs :  1  No wins :  0\n",
        "Wins : \n",
        " DT10 :  7  Other DTs :  2  No wins :  0\n",
        "Wins : \n",
        " DT10 :  6  Other DTs :  3  No wins :  0\n",
        "Wins : \n",
        " DT10 :  7  Other DTs :  2  No wins :  0\n",
        " '''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTMhMMpFMhLo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Download the Dataset to be processed in Assignment 2\n",
        "#2000*10= 20000; 20000-2000=18000 rows if nobody wins for all games.\n",
        "#from google.colab import files\n",
        "#datatbp.to_csv('CE888_DataToBeProcessed_1900690.csv')\n",
        "#files.download('CE888_DataToBeProcessed_1900690.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nt6ny6ZKg93-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import os\n",
        "#print(os.getcwd())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QIVKeKsgCd6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get data set from Drive\n",
        "#Data=pd.read_csv('CE888_DataToBeProcessed_1900690_6261Wins.csv')\n",
        "#Data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmDcom6amnPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}